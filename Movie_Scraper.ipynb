{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException, WebDriverException\n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMDB_URL_MOVIES = r'https://www.imdb.com/chart/top/?ref_=nv_mv_250'\n",
    "LETTERBOXD_MOVIES = r'https://letterboxd.com/dave/list/official-top-250-narrative-feature-films/'\n",
    "ROTTEN_TOMATOES_MOVIES = r'https://editorial.rottentomatoes.com/guide/best-movies-of-all-time/'\n",
    "str1 = r'https://www.imdb.com'\n",
    "str2 = r'https://letterboxd.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "links1 = set()\n",
    "links3 = set()\n",
    "links4 = set()\n",
    "\n",
    "data_imdb_movies = { 'Title' : [] , 'Link' : [] , 'Year' : [] , 'Rating_Classification' : [] , 'Runtime' : [] , 'Total_Ratings' : [] , 'Average_Rating' : [] , 'Genre' : [] , 'Director' : [] }\n",
    "data_letterbox_movies = { 'Title' : [] , 'Link' : [] , 'Year' : []  , 'Runtime' : [] , 'Average_n_total_Rating' : [] , 'Genre' : [] , 'Director' : [] }\n",
    "data_rotten_tomatoes_movies = { 'Title' : [] , 'Link' : [] , 'Year' : [] , 'Runtime' : [] , 'Rating_Classification' : [] , 'Runtime' : [] , 'Total_Ratings' : [] , 'Critic_Score' : [] , 'Audience_Score' : [] , 'Genre' : [] , 'Director' : [] }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # IMDB Movies\n",
    "try:\n",
    "     # opening the page \n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get( IMDB_URL_MOVIES )\n",
    "    driver.maximize_window()\n",
    "    driver.execute_script(\"document.body.style.zoom='100%'\")\n",
    "\n",
    "    while True:\n",
    "        # Create an explicit wait object\n",
    "        wait = WebDriverWait(driver, 20)\n",
    "\n",
    "         # Wait for an element to be present\n",
    "        elements = wait.until(EC.presence_of_all_elements_located(( By.CSS_SELECTOR, 'a.ipc-title-link-wrapper[href]') ))\n",
    "\n",
    "        html1 = driver.page_source\n",
    "\n",
    "         # Creating a soup object \n",
    "        main_soup = BeautifulSoup( html1 , 'lxml' )\n",
    "\n",
    "         # Getting the link\n",
    "        link_attr = main_soup.select('a.ipc-title-link-wrapper[href]')\n",
    "\n",
    "        for element in link_attr:\n",
    "             \n",
    "            link = element.get( 'href' )\n",
    "            \n",
    "             # Adding the imdb.com\n",
    "            link = str1 + link\n",
    "\n",
    "            if link in links1:\n",
    "                continue\n",
    "            else:\n",
    "                links1.add(link)\n",
    "                data_imdb_movies['Link'].append(link) \n",
    "\n",
    "                driver.get(link)\n",
    "                sleep(1)\n",
    "\n",
    "                 # Getting the data using bs4\n",
    "                div_elem = wait.until(EC.presence_of_element_located(( By.CSS_SELECTOR, 'div.sc-70a366cc-0.bxYZmb') ))\n",
    "\n",
    "\n",
    "                if div_elem:\n",
    "                     # Getting the html \n",
    "                    html = driver.page_source\n",
    "\n",
    "                     # Beautiful Soup object\n",
    "                    soup_2 = BeautifulSoup( html , 'lxml' )\n",
    "\n",
    "                    div_attr = soup_2.select( 'div.sc-70a366cc-0.bxYZmb')\n",
    "                    \n",
    "                     # Getting the data in div elements\n",
    "                    for elements in div_attr:\n",
    "                        \n",
    "                         # Getting the Title \n",
    "                        title_attr = elements.select('span.hero__primary-text')\n",
    "\n",
    "                        if  title_attr:\n",
    "                   \n",
    "                            title = title_attr[0].get_text().strip()\n",
    "\n",
    "                            data_imdb_movies['Title'].append(title)\n",
    "                        \n",
    "\n",
    "                        else:\n",
    "\n",
    "                            data_imdb_movies['Title'].append('')\n",
    "\n",
    "                         # Getting the year , Rating classification and runtime\n",
    "                        li_attr = elements.select('li.ipc-inline-list__item')\n",
    "            \n",
    "                        if li_attr:\n",
    "\n",
    "                            if len(li_attr) == 3 :\n",
    "\n",
    "                                year = li_attr[0].get_text()\n",
    "                                data_imdb_movies['Year'].append(year)\n",
    "\n",
    "                                rating_classification = li_attr[1].get_text()\n",
    "                                data_imdb_movies['Rating_Classification'].append(rating_classification)\n",
    "                \n",
    "                                runtime = li_attr[2].get_text()\n",
    "                                data_imdb_movies['Runtime'].append(runtime)\n",
    "\n",
    "                            else:\n",
    "                                \n",
    "                                data_imdb_movies['Rating_Classification'].append('CHECK')\n",
    "\n",
    "                                data = ''\n",
    "\n",
    "                                for i in li_attr:\n",
    "\n",
    "                                    x = i.get_text()\n",
    "                                    \n",
    "                                    if data:\n",
    "\n",
    "                                        data += '|'\n",
    "\n",
    "                                    data += x\n",
    "\n",
    "                                data_imdb_movies['Year'].append(data)\n",
    "\n",
    "                                data_imdb_movies['Runtime'].append('CHECK')\n",
    "\n",
    "\n",
    "                                \n",
    "                        else:\n",
    "\n",
    "                            data_imdb_movies['year'].append('')\n",
    "                            data_imdb_movies['Runtime'].append('')\n",
    "                            data_imdb_movies['Rating_Classification'].append('')\n",
    "\n",
    "\n",
    "\n",
    "                     # Getting the Total Ratings \n",
    "                    ratings_attr = soup_2.select('div.sc-d541859f-3.dwhNqC')\n",
    "\n",
    "                    if ratings_attr:\n",
    "\n",
    "                        total_Ratings = ratings_attr[0].get_text().strip()\n",
    "                        data_imdb_movies['Total_Ratings'].append(total_Ratings)\n",
    "\n",
    "                    else:\n",
    "\n",
    "                        data_imdb_movies['Total_Ratings'].append('')\n",
    "\n",
    "                     # Getting Average Rating\n",
    "                    avg_rating_attr = soup_2.select('div[data-testid=\"hero-rating-bar__aggregate-rating__score\"]')\n",
    "\n",
    "                    if avg_rating_attr:\n",
    "\n",
    "                        avg_rating = avg_rating_attr[0].get_text().strip()\n",
    "                        data_imdb_movies['Average_Rating'].append(avg_rating)\n",
    "\n",
    "                    else:\n",
    "\n",
    "                        data_imdb_movies['Average_Rating'].append('')\n",
    "\n",
    "                     # Getting Genre\n",
    "                    genre_attr = soup_2.select('span.ipc-chip__text')\n",
    "\n",
    "                    if genre_attr: \n",
    "\n",
    "                        if len(genre_attr) >= 3:\n",
    "\n",
    "                            genre = genre_attr[0].get_text().strip() + '|' + genre_attr[1].get_text().strip() + '|' + genre_attr[2].get_text().strip()\n",
    "                            data_imdb_movies['Genre'].append(genre)\n",
    "\n",
    "                        else:\n",
    "\n",
    "                            genre = ''\n",
    "\n",
    "                            for i in genre_attr:\n",
    "                                 \n",
    "                                x = i.get_text()\n",
    "\n",
    "                                if genre:\n",
    "\n",
    "                                    genre += '|'\n",
    "\n",
    "                                genre += x\n",
    "\n",
    "                            data_imdb_movies['Genre'].append(genre)\n",
    "                                \n",
    "\n",
    "                    else:\n",
    "\n",
    "                        data_imdb_movies['Genre'].append('')\n",
    "\n",
    "                     # Getting the Director\n",
    "                    dir_attr = soup_2.select('a.ipc-metadata-list-item__list-content-item.ipc-metadata-list-item__list-content-item--link')\n",
    "\n",
    "                    if dir_attr:\n",
    "\n",
    "                        director = dir_attr[0].get_text().strip()\n",
    "                        data_imdb_movies['Director'].append(director)\n",
    "\n",
    "                    else:\n",
    "\n",
    "                        data_imdb_movies['Director'].append('')\n",
    "\n",
    "                driver.back()\n",
    "                sleep(1)\n",
    "\n",
    "                 # Breaking \n",
    "                if len(links1)>= 250:\n",
    "                    break\n",
    "                \n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "\n",
    "except WebDriverException as web_err:\n",
    "    print(f'Selenium WebDriver error occurred: {web_err}')\n",
    "except Exception as e:\n",
    "    print(f'An error occurred: {e}')\n",
    "\n",
    "finally:\n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Saving the IMDB Movies as a json file\n",
    "\n",
    "with open('IMDB_DATA.json', mode='w', encoding='utf-8') as file:\n",
    "    # Write the data dictionary to the file as JSON\n",
    "    json.dump(data_imdb_movies, file, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    " # scrolling in small increments\n",
    "increment = 0.99 # Scroll by 50% of the remaining page height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100\n",
      "50\n",
      "No Next Button\n"
     ]
    }
   ],
   "source": [
    " # LETTERBOXD MOVIES\n",
    "try:\n",
    "     # opening the page \n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get( LETTERBOXD_MOVIES )\n",
    "    driver.maximize_window()\n",
    "    driver.execute_script(\"document.body.style.zoom='100%'\")\n",
    "\n",
    "    while True:\n",
    "        # Create an explicit wait object\n",
    "        wait = WebDriverWait(driver, 20)\n",
    "\n",
    "         # Wait for an element to be present\n",
    "        elements = wait.until(EC.presence_of_all_elements_located(( By.CSS_SELECTOR, 'a.frame[href]') ))\n",
    "\n",
    "        for i in range(4):\n",
    "\n",
    "            scroll_position = driver.execute_script(\"return window.pageYOffset + window.innerHeight + window.innerHeight * {0}\".format(increment))\n",
    "    \n",
    "             # Scroll by the incremented amount\n",
    "            driver.execute_script(f\"window.scrollTo(0, {scroll_position});\")\n",
    "\n",
    "            sleep(3)\n",
    "\n",
    "\n",
    "        html1 = driver.page_source\n",
    "\n",
    "         # Creating a soup object \n",
    "        main_soup = BeautifulSoup( html1 , 'lxml' )\n",
    "\n",
    "        link_attr = main_soup.select('a.frame')\n",
    "\n",
    "        print(len(link_attr))\n",
    "        \n",
    "        for element in link_attr:\n",
    "\n",
    "            link = element.get('href')\n",
    "            \n",
    "             # Adding letterboxd.com\n",
    "            link = str2 + link \n",
    "            \n",
    "            if link in links3:\n",
    "                continue\n",
    "            else:\n",
    "                #links3.add(link)\n",
    "                #data_letterbox_movies['Link'].append(link) \n",
    "\n",
    "                driver.get(link)\n",
    "                sleep(1)\n",
    "\n",
    "                title_elem = wait.until(EC.presence_of_all_elements_located(( By.CSS_SELECTOR, 'span.name.js-widont.prettify') ))\n",
    "\n",
    "                if title_elem:\n",
    "                    \n",
    "                    html = driver.page_source\n",
    "                    \n",
    "                     # Beautiful Soup object\n",
    "                    soup_2 = BeautifulSoup( html , 'lxml' )\n",
    "\n",
    "                     # getting the Title\n",
    "                    title_attr = soup_2.select('span.name.js-widont.prettify')\n",
    "\n",
    "                    if title_attr :\n",
    "\n",
    "                        title = title_attr[0].get_text()\n",
    "                        data_letterbox_movies['Title'].append(title)\n",
    "\n",
    "                    else:\n",
    "\n",
    "                        data_letterbox_movies['Title'].append('')\n",
    "\n",
    "                     # Getting the year\n",
    "                    year_attr = soup_2.select('div.releaseyear')\n",
    "\n",
    "                    if year_attr :\n",
    "\n",
    "                        year = year_attr[0].get_text()\n",
    "                        data_letterbox_movies['Year'].append(year)\n",
    "\n",
    "                    else:\n",
    "\n",
    "                        data_letterbox_movies['Year'].append('')\n",
    "\n",
    "                     # Getting the Director\n",
    "                    dir_attr = soup_2.select('span.directorlist')\n",
    "\n",
    "                    if dir_attr :\n",
    "\n",
    "                        director = dir_attr[0].get_text()\n",
    "                        data_letterbox_movies['Director'].append(director)\n",
    "\n",
    "                    else:\n",
    "\n",
    "                        data_letterbox_movies['Director'].append('')    \n",
    "\n",
    "                     # Getting the Runtime\n",
    "                    runtime_attr = soup_2.select('p.text-link.text-footer')\n",
    "\n",
    "                    if runtime_attr :\n",
    "\n",
    "                        runtime = runtime_attr[0].get_text()\n",
    "                        data_letterbox_movies['Runtime'].append(runtime)\n",
    "\n",
    "                    else:\n",
    "\n",
    "                        data_letterbox_movies['Runtime'].append('')                  \n",
    "               \n",
    "                     # Getting the average weighted rating and total ratings\n",
    "                    a_tag = soup_2.select_one('span.average-rating a.tooltip.display-rating.-highlight')\n",
    "\n",
    "                    \n",
    "                    if a_tag:\n",
    "\n",
    "                        original_title = a_tag.get('data-original-title')\n",
    "\n",
    "                        data_letterbox_movies['Average_n_total_Rating'].append(original_title)\n",
    "                    \n",
    "                    else:\n",
    "\n",
    "                        data_letterbox_movies['Average_n_total_Rating'].append('')\n",
    "\n",
    "                    div_genre = soup_2.select('div[id=\"tab-genres\"]')\n",
    "\n",
    "                    for elements in div_genre:\n",
    "\n",
    "                        genre_attr = elements.select('a.text-slug')\n",
    "\n",
    "                        if genre_attr :\n",
    "                            \n",
    "                            genre = genre_attr[0].get_text()\n",
    "                            data_letterbox_movies['Genre'].append(genre)\n",
    "\n",
    "                        else :\n",
    "\n",
    "                            data_letterbox_movies['Genre'].append('')\n",
    "                \n",
    "                links3.add(link)\n",
    "                data_letterbox_movies['Link'].append(link)\n",
    "                \n",
    "                driver.back()\n",
    "                sleep(1)\n",
    "\n",
    "        next_button = main_soup.select('a.next')\n",
    "\n",
    "        if next_button:\n",
    "            \n",
    "            for elements in  next_button:\n",
    "\n",
    "                next_link = next_button[0].get('href')\n",
    "\n",
    "                link = str2 + next_link\n",
    "\n",
    "                driver.get(link) \n",
    "                \n",
    "                continue \n",
    "\n",
    "        else:\n",
    "            print('No Next Button')\n",
    "            break     \n",
    "                    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "except WebDriverException as web_err:\n",
    "    print(f'Selenium WebDriver error occurred: {web_err}')\n",
    "except Exception as e:\n",
    "    print(f'An error occurred: {e}')\n",
    "\n",
    "finally:\n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Saving the Data \n",
    "\n",
    "with open('Letterbox_Data.json', mode='w', encoding='utf-8') as file:\n",
    "    # Write the data dictionary to the file as JSON\n",
    "    json.dump(data_letterbox_movies, file, ensure_ascii=False, indent=4)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # ROTTEN TOMATOES MOVIES\n",
    "\n",
    "try:\n",
    "     # opening the page \n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get( ROTTEN_TOMATOES_MOVIES )\n",
    "    driver.maximize_window()\n",
    "    driver.execute_script(\"document.body.style.zoom='100%'\")\n",
    "\n",
    "    while True:\n",
    "        # Create an explicit wait object\n",
    "        wait = WebDriverWait(driver, 20)\n",
    "\n",
    "         # Wait for an element to be present\n",
    "        elements = wait.until(EC.presence_of_all_elements_located(( By.CSS_SELECTOR, 'a.title[href]') ))\n",
    "\n",
    "        html1 = driver.page_source\n",
    "\n",
    "         # Creating a soup object \n",
    "        main_soup = BeautifulSoup( html1 , 'lxml' )\n",
    "\n",
    "        link_attr = main_soup.select('a.title')\n",
    "\n",
    "        for element in link_attr:\n",
    "            \n",
    "            link = element.get('href')\n",
    "\n",
    "            if link in links4:\n",
    "                continue\n",
    "\n",
    "            else:\n",
    "\n",
    "                links4.add(link)\n",
    "                data_rotten_tomatoes_movies['Link'].append(link)\n",
    "\n",
    "                driver.get(link)\n",
    "                sleep(1)\n",
    "\n",
    "                title_elem = wait.until(EC.presence_of_all_elements_located(( By.CSS_SELECTOR, 'rt-text[slot=\"title\"]') ))\n",
    "\n",
    "                if title_elem:\n",
    "\n",
    "                    html = driver.page_source\n",
    "                    \n",
    "                     # Beautiful Soup object\n",
    "                    soup_2 = BeautifulSoup( html , 'lxml' )\n",
    "\n",
    "                     # getting the Title\n",
    "                    title_attr = soup_2.select('rt-text[slot=\"title\"]')\n",
    "\n",
    "                    if title_attr :\n",
    "\n",
    "                        title = title_attr[0].get_text()\n",
    "                        data_rotten_tomatoes_movies['Title'].append(title)\n",
    "\n",
    "                    else:\n",
    "\n",
    "                        data_rotten_tomatoes_movies['Title'].append('')\n",
    "                    \n",
    "                     # getting the rating ,release date and runtime\n",
    "                    element1 = soup_2.select('rt-text[slot=\"metadataProp\"]')\n",
    "\n",
    "                    if element1 :\n",
    "\n",
    "                        if len(element1) == 3:\n",
    "\n",
    "                            rating = element1[0].get_text()\n",
    "                            data_rotten_tomatoes_movies['Rating_Classification'].append(rating)\n",
    "\n",
    "                            release_date = element1[1].get_text()\n",
    "                            data_rotten_tomatoes_movies['Year'].append(release_date)\n",
    "\n",
    "                            runtime = element1[2].get_text()\n",
    "                            data_rotten_tomatoes_movies['Runtime'].append(runtime)\n",
    "\n",
    "                        else :\n",
    "\n",
    "                            data_rotten_tomatoes_movies['Rating_Classification'].append('CHECK')\n",
    "                            \n",
    "                            data = ''\n",
    "\n",
    "                            for i in element1:\n",
    "\n",
    "                                x = i.get_text()\n",
    "\n",
    "                                if data:\n",
    "                                    data += '|'\n",
    "\n",
    "                                data += x\n",
    "\n",
    "                            data_rotten_tomatoes_movies['Year'].append(data)\n",
    "\n",
    "                            data_rotten_tomatoes_movies['Runtime'].append('CHECK')\n",
    "                            \n",
    "                    else:\n",
    "\n",
    "                        data_rotten_tomatoes_movies['Rating_Classification'].append('')\n",
    "                        data_rotten_tomatoes_movies['Year'].append('')\n",
    "                        data_rotten_tomatoes_movies['Runtime'].append('')\n",
    "\n",
    "                     # Getting Genre\n",
    "                    genre_attr = soup_2.select('rt-text[slot=\"metadataGenre\"]')\n",
    "\n",
    "                    if genre_attr:\n",
    "\n",
    "                        genre = genre_attr[0].get_text()\n",
    "                        data_rotten_tomatoes_movies['Genre'].append(genre)\n",
    "\n",
    "                    else:\n",
    "\n",
    "                        data_rotten_tomatoes_movies['Genre'].append('')\n",
    "\n",
    "                     # Getting the Critic score\n",
    "                    critic_attr = soup_2.select('rt-text[slot=\"criticsScore\"]')\n",
    "\n",
    "                    if critic_attr:\n",
    "\n",
    "                        critic_score = critic_attr[0].get_text()\n",
    "                        data_rotten_tomatoes_movies['Critic_Score'].append(critic_score)\n",
    "\n",
    "                    else:\n",
    "\n",
    "                        data_rotten_tomatoes_movies['Critic_Score'].append('')\n",
    "\n",
    "                     # Getting the audience score\n",
    "                    audience_attr = soup_2.select('rt-text[slot=\"audienceScore\"]')\n",
    "\n",
    "                    if audience_attr:\n",
    "\n",
    "                        audience_score = audience_attr[0].get_text()\n",
    "                        data_rotten_tomatoes_movies['Audience_Score'].append(audience_score)\n",
    "\n",
    "                    else:\n",
    "\n",
    "                        data_rotten_tomatoes_movies['Audience_Score'].append('')\n",
    "\n",
    "\n",
    "                     # Getting the Total Ratings\n",
    "                    ratings_attr = soup_2.select('rt-link[slot=\"audienceReviews\"]')\n",
    "\n",
    "                    if ratings_attr:\n",
    "\n",
    "                        total_Ratings = ratings_attr[0].get_text()\n",
    "                        data_rotten_tomatoes_movies['Total_Ratings'].append(total_Ratings)\n",
    "\n",
    "                    else:\n",
    "\n",
    "                        data_rotten_tomatoes_movies['Total_Ratings'].append('')\n",
    "\n",
    "                     # Getting the Director\n",
    "                    dir_attr = soup_2.select('p.name')\n",
    "\n",
    "                    if dir_attr:\n",
    "\n",
    "                        director = dir_attr[0].get_text()\n",
    "                        data_rotten_tomatoes_movies['Director'].append(director)\n",
    "\n",
    "                    else:\n",
    "\n",
    "                        data_rotten_tomatoes_movies['Director'].append('')\n",
    "                \n",
    "                driver.back()\n",
    "                sleep(1)\n",
    "\n",
    "                # Breaking the loop at 200\n",
    "                if len(links4) >= 299:\n",
    "                    \n",
    "                    break\n",
    "\n",
    "                else :\n",
    "                    continue\n",
    "\n",
    "\n",
    "\n",
    "except WebDriverException as web_err:\n",
    "    print(f'Selenium WebDriver error occurred: {web_err}')\n",
    "except Exception as e:\n",
    "    print(f'An error occurred: {e}')\n",
    "\n",
    "finally:\n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Saving the Data\n",
    "with open('Rotten_Tomatoes_Data.json', mode='w', encoding='utf-8') as file:\n",
    "    # Write the data dictionary to the file as JSON\n",
    "    json.dump(data_rotten_tomatoes_movies, file, ensure_ascii=False, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
